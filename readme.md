# ğŸ“ TutorMind â€“ AI-Powered Personalized Tutor

TutorMind is a document-grounded GenAI assistant that transforms your files into an intelligent tutor. Powered by Retrieval-Augmented Generation (RAG), LangChain, and multiple LLMs, TutorMind helps users ask **precise, contextual questions** from **PDFs, DOCX, TXT, or even image-based content**.

---

## ğŸš€ What's New in Version 2.0

* ğŸ” **Multi-Model Backend**: Supports Groq, OpenRouter, HuggingFace, and Local inference with dynamic routing
* ğŸ“ **Multi-File Uploads**: Supports PDF, DOCX, TXT, and images with OCR fallback
* ğŸ“‚ **File-Specific QA**: Select files to ask questions from and see file-specific source context
* ğŸ§  **Dual QA Modes**: Switch between Conceptual (LLM) and Factual (BERT extractive) answering
* ğŸ” **Adaptive Chunking**: Uses clustering on sentence embeddings for intelligent segmentation
* ğŸ“Š **User Insights**: Tracks questions asked, average answer length, and session stats
* ğŸ—³ï¸ **Feedback System**: Rate your experience and submit optional comments
* âœ… **Improved UI/UX**: Tabbed layout, clean session handling, and model info comparison

---

## ğŸ“ˆ Tech Stack

| Layer      | Stack                                    |
| ---------- | ---------------------------------------- |
| Frontend   | Streamlit                                |
| Backend    | Python + LangChain                       |
| LLMs       | Groq, OpenRouter, HuggingFace, Local     |
| Embeddings | all-MiniLM-L6-v2 (sentence-transformers) |
| Vector DB  | FAISS                                    |
| Auth + DB  | Firebase Firestore                       |

---

## ğŸ¤– How It Works

1. **User Login/Register** (Firestore-auth)
2. **Upload files** (PDF/DOCX/TXT/Images)
3. **Text extracted + chunked** using ML-based adaptive chunking
4. **Embeddings stored** in FAISS
5. **Question asked â†’ RAG pipeline** triggered
6. **Answer generated** using chosen LLM (Factual or Generative)
7. **Answer & source chunks returned**
8. **Session saved per user in Firestore**

---

## ğŸ§  Model Architecture

| Mode       | Model Examples                            | Use Case                           |
| ---------- | ----------------------------------------- | ---------------------------------- |
| Extractive | BERT (deepset/squad2)                     | Direct factual Qs                  |
| Generative | LLaMA3, Mistral, Flan-T5, OpenChat, etc.  | Why/How/Conceptual Qs              |
| Backend    | Dynamic `query_model()` abstraction layer | Unified across Groq/OpenRouter/etc |

---

## ğŸ” Authentication

* ğŸ”‘ Firebase-backed login and registration
* ğŸ”’ Passwords securely hashed (SHA-256)
* ğŸ” Password change support
* ğŸ§  Session-based state with Streamlit

---

## âœ¨ Key Features

* ğŸ“ Upload any document (PDF, DOCX, TXT, IMG)
* ğŸ§  Ask deep or factual questions from your content
* ğŸ“‚ Ask from specific files only
* ğŸ“„ View exact source context with file label
* ğŸ” Clear Q\&A history or uploaded files
* ğŸ§  Model + QA Mode switching (Groq / OpenRouter / HuggingFace)
* ğŸ“Š See insights on session activity (e.g., longest answer)
* ğŸ—£ï¸ Submit feedback directly
* âœ… Fully deployable on Streamlit Cloud

---

## ğŸ§ª Future Enhancements

* ğŸ—¨ï¸ Real-time Chat Mode with memory
* ğŸ“ˆ Admin dashboard & analytics
* ğŸ¯ Adaptive reranking based on feedback
* ğŸ“¤ Export sessions to PDF or shareable link
* ğŸ—£ï¸ Whisper voice input

---

## ğŸ“˜ License

MIT License â€“ Free for personal, academic, or educational use.

---

## âœ¨ Made with â¤ï¸ by Shashank using GenAI, LangChain, and Streamlit
